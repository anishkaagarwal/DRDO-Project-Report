{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70056487",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "\n",
    "# Example data (use your own dataset here)\n",
    "X, y = np.load('Features.xlsx'), np.load('Labels.xlsx')\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(input_dim,)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c888d572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.17.0-cp39-cp39-win_amd64.whl (2.0 kB)\n",
      "Collecting tensorflow-intel==2.17.0\n",
      "  Using cached tensorflow_intel-2.17.0-cp39-cp39-win_amd64.whl (385.0 MB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (63.4.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.14.1)\n",
      "Collecting keras>=3.2.0\n",
      "  Using cached keras-3.4.1-py3-none-any.whl (1.1 MB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.65.4-cp39-cp39-win_amd64.whl (4.1 MB)\n",
      "Collecting flatbuffers>=24.3.25\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (21.3)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Collecting tensorboard<2.18,>=2.17\n",
      "  Using cached tensorboard-2.17.0-py3-none-any.whl (5.5 MB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.28.1)\n",
      "Collecting h5py>=3.10.0\n",
      "  Using cached h5py-3.11.0-cp39-cp39-win_amd64.whl (3.0 MB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.3.0)\n",
      "Collecting numpy<2.0.0,>=1.23.5\n",
      "  Using cached numpy-1.26.4-cp39-cp39-win_amd64.whl (15.8 MB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Using cached protobuf-4.25.4-cp39-cp39-win_amd64.whl (413 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.3.1\n",
      "  Using cached ml_dtypes-0.4.0-cp39-cp39-win_amd64.whl (126 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.37.1)\n",
      "Collecting rich\n",
      "  Using cached rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "Collecting optree\n",
      "  Using cached optree-0.12.1-cp39-cp39-win_amd64.whl (263 kB)\n",
      "Collecting namex\n",
      "  Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.0.3)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from packaging->tensorflow-intel==2.17.0->tensorflow) (3.0.9)\n",
      "Collecting typing-extensions>=3.6.6\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Collecting pygments<3.0.0,>=2.13.0\n",
      "  Using cached pygments-2.18.0-py3-none-any.whl (1.2 MB)\n",
      "Collecting mdurl~=0.1\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, pygments, protobuf, numpy, mdurl, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, optree, opt-einsum, ml-dtypes, markdown-it-py, h5py, rich, keras, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.3.0\n",
      "    Uninstalling typing_extensions-4.3.0:\n",
      "      Successfully uninstalled typing_extensions-4.3.0\n",
      "  Attempting uninstall: pygments\n",
      "    Found existing installation: Pygments 2.11.2\n",
      "    Uninstalling Pygments-2.11.2:\n",
      "      Successfully uninstalled Pygments-2.11.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.5\n",
      "    Uninstalling numpy-1.21.5:\n",
      "      Successfully uninstalled numpy-1.21.5\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.7.0\n",
      "    Uninstalling h5py-3.7.0:\n",
      "      Successfully uninstalled h5py-3.7.0\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.65.4 h5py-3.11.0 keras-3.4.1 libclang-18.1.1 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.0 namex-0.0.8 numpy-1.26.4 opt-einsum-3.3.0 optree-0.12.1 protobuf-4.25.4 pygments-2.18.0 rich-13.7.1 tensorboard-2.17.0 tensorboard-data-server-0.7.2 tensorflow-2.17.0 tensorflow-intel-2.17.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.4.0 typing-extensions-4.12.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.2.2 requires pyqt5<5.13, which is not installed.\n",
      "spyder 5.2.2 requires pyqtwebengine<5.13, which is not installed.\n",
      "daal4py 2021.6.0 requires daal==2021.4.0, which is not installed.\n",
      "scipy 1.9.1 requires numpy<1.25.0,>=1.18.5, but you have numpy 1.26.4 which is incompatible.\n",
      "numba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 1.26.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "476bf3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyqt5\n",
      "  Downloading PyQt5-5.15.11-cp38-abi3-win_amd64.whl (6.9 MB)\n",
      "     ---------------------------------------- 6.9/6.9 MB 1.2 MB/s eta 0:00:00\n",
      "Collecting pyqtwebengine\n",
      "  Downloading PyQtWebEngine-5.15.7-cp38-abi3-win_amd64.whl (184 kB)\n",
      "     -------------------------------------- 184.7/184.7 kB 2.2 MB/s eta 0:00:00\n",
      "Collecting PyQt5-Qt5<5.16.0,>=5.15.2\n",
      "  Downloading PyQt5_Qt5-5.15.2-py3-none-win_amd64.whl (50.1 MB)\n",
      "     ---------------------------------------- 50.1/50.1 MB 3.2 MB/s eta 0:00:00\n",
      "Collecting PyQt5-sip<13,>=12.15\n",
      "  Using cached PyQt5_sip-12.15.0-cp39-cp39-win_amd64.whl (59 kB)\n",
      "Collecting PyQtWebEngine-Qt5<5.16.0,>=5.15.0\n",
      "  Downloading PyQtWebEngine_Qt5-5.15.2-py3-none-win_amd64.whl (60.0 MB)\n",
      "     ---------------------------------------- 60.0/60.0 MB 3.3 MB/s eta 0:00:00\n",
      "Installing collected packages: PyQtWebEngine-Qt5, PyQt5-Qt5, PyQt5-sip, pyqt5, pyqtwebengine\n",
      "Successfully installed PyQt5-Qt5-5.15.2 PyQt5-sip-12.15.0 PyQtWebEngine-Qt5-5.15.2 pyqt5-5.15.11 pyqtwebengine-5.15.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.2.2 requires pyqt5<5.13, but you have pyqt5 5.15.11 which is incompatible.\n",
      "spyder 5.2.2 requires pyqtwebengine<5.13, but you have pyqtwebengine 5.15.7 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install pyqt5 pyqtwebengine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9442dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.21.6\n",
      "  Using cached numpy-1.21.6-cp39-cp39-win_amd64.whl (14.0 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "Successfully installed numpy-1.21.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.6.0 requires daal==2021.4.0, which is not installed.\n",
      "tensorflow-intel 2.17.0 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 1.21.6 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.21.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f27a234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting daal==2021.4.0\n",
      "  Downloading daal-2021.4.0-py2.py3-none-win_amd64.whl (69.0 MB)\n",
      "     ---------------------------------------- 69.0/69.0 MB 3.0 MB/s eta 0:00:00\n",
      "Collecting tbb==2021.*\n",
      "  Downloading tbb-2021.13.0-py3-none-win_amd64.whl (286 kB)\n",
      "     -------------------------------------- 286.9/286.9 kB 3.5 MB/s eta 0:00:00\n",
      "Installing collected packages: tbb, daal\n",
      "  Attempting uninstall: tbb\n",
      "    Found existing installation: TBB 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Cannot uninstall 'TBB'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\n"
     ]
    }
   ],
   "source": [
    "!pip install daal==2021.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c8baddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.17.0-cp39-cp39-win_amd64.whl (2.0 kB)\n",
      "Collecting tensorflow-intel==2.17.0\n",
      "  Using cached tensorflow_intel-2.17.0-cp39-cp39-win_amd64.whl (385.0 MB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.3.1\n",
      "  Using cached ml_dtypes-0.4.0-cp39-cp39-win_amd64.whl (126 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Collecting flatbuffers>=24.3.25\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Collecting packaging\n",
      "  Using cached packaging-24.1-py3-none-any.whl (53 kB)\n",
      "Collecting numpy<2.0.0,>=1.23.5\n",
      "  Using cached numpy-1.26.4-cp39-cp39-win_amd64.whl (15.8 MB)\n",
      "Collecting keras>=3.2.0\n",
      "  Using cached keras-3.4.1-py3-none-any.whl (1.1 MB)\n",
      "Collecting h5py>=3.10.0\n",
      "  Using cached h5py-3.11.0-cp39-cp39-win_amd64.whl (3.0 MB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.65.4-cp39-cp39-win_amd64.whl (4.1 MB)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Collecting typing-extensions>=3.6.6\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "     -------------------------------------- 64.9/64.9 kB 497.2 kB/s eta 0:00:00\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.16.0-cp39-cp39-win_amd64.whl (37 kB)\n",
      "Collecting setuptools\n",
      "  Downloading setuptools-72.1.0-py3-none-any.whl (2.3 MB)\n",
      "     ---------------------------------------- 2.3/2.3 MB 1.7 MB/s eta 0:00:00\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Using cached protobuf-4.25.4-cp39-cp39-win_amd64.whl (413 kB)\n",
      "Collecting six>=1.12.0\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting tensorboard<2.18,>=2.17\n",
      "  Using cached tensorboard-2.17.0-py3-none-any.whl (5.5 MB)\n",
      "Collecting wheel<1.0,>=0.23.0\n",
      "  Downloading wheel-0.44.0-py3-none-any.whl (67 kB)\n",
      "     ---------------------------------------- 67.1/67.1 kB 3.6 MB/s eta 0:00:00\n",
      "Collecting namex\n",
      "  Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Collecting rich\n",
      "  Using cached rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "Collecting optree\n",
      "  Using cached optree-0.12.1-cp39-cp39-win_amd64.whl (263 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.3.2-cp39-cp39-win_amd64.whl (100 kB)\n",
      "     -------------------------------------- 100.4/100.4 kB 2.9 MB/s eta 0:00:00\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.7-py3-none-any.whl (66 kB)\n",
      "     ---------------------------------------- 66.8/66.8 kB 1.8 MB/s eta 0:00:00\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.2.2-py3-none-any.whl (121 kB)\n",
      "     -------------------------------------- 121.4/121.4 kB 2.4 MB/s eta 0:00:00\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2024.7.4-py3-none-any.whl (162 kB)\n",
      "     -------------------------------------- 163.0/163.0 kB 2.4 MB/s eta 0:00:00\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "     -------------------------------------- 105.4/105.4 kB 3.1 MB/s eta 0:00:00\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading werkzeug-3.0.3-py3-none-any.whl (227 kB)\n",
      "     -------------------------------------- 227.3/227.3 kB 2.3 MB/s eta 0:00:00\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Downloading importlib_metadata-8.2.0-py3-none-any.whl (25 kB)\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Downloading MarkupSafe-2.1.5-cp39-cp39-win_amd64.whl (17 kB)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Collecting pygments<3.0.0,>=2.13.0\n",
      "  Using cached pygments-2.18.0-py3-none-any.whl (1.2 MB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.19.2-py3-none-any.whl (9.0 kB)\n",
      "Collecting mdurl~=0.1\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, zipp, wrapt, wheel, urllib3, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, six, setuptools, pygments, protobuf, packaging, numpy, mdurl, MarkupSafe, idna, grpcio, gast, charset-normalizer, certifi, absl-py, werkzeug, requests, optree, opt-einsum, ml-dtypes, markdown-it-py, importlib-metadata, h5py, google-pasta, astunparse, rich, markdown, tensorboard, keras, tensorflow-intel, tensorflow\n",
      "Successfully installed MarkupSafe-2.1.5 absl-py-2.1.0 astunparse-1.6.3 certifi-2024.7.4 charset-normalizer-3.3.2 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.65.4 h5py-3.11.0 idna-3.7 importlib-metadata-8.2.0 keras-3.4.1 libclang-18.1.1 markdown-3.6 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.0 namex-0.0.8 numpy-1.26.4 opt-einsum-3.3.0 optree-0.12.1 packaging-24.1 protobuf-4.25.4 pygments-2.18.0 requests-2.32.3 rich-13.7.1 setuptools-72.1.0 six-1.16.0 tensorboard-2.17.0 tensorboard-data-server-0.7.2 tensorflow-2.17.0 tensorflow-intel-2.17.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.4.0 typing-extensions-4.12.2 urllib3-2.2.2 werkzeug-3.0.3 wheel-0.44.0 wrapt-1.16.0 zipp-3.19.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.6.0 requires daal==2021.4.0, which is not installed.\n",
      "anaconda-project 0.11.1 requires ruamel-yaml, which is not installed.\n",
      "spyder 5.2.2 requires pyqt5<5.13, but you have pyqt5 5.15.11 which is incompatible.\n",
      "spyder 5.2.2 requires pyqtwebengine<5.13, but you have pyqtwebengine 5.15.7 which is incompatible.\n",
      "scipy 1.9.1 requires numpy<1.25.0,>=1.18.5, but you have numpy 1.26.4 which is incompatible.\n",
      "numba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 1.26.4 which is incompatible.\n",
      "conda-repo-cli 1.0.20 requires clyent==1.2.1, but you have clyent 1.2.2 which is incompatible.\n",
      "conda-repo-cli 1.0.20 requires nbformat==5.4.0, but you have nbformat 5.5.0 which is incompatible.\n",
      "conda-repo-cli 1.0.20 requires requests==2.28.1, but you have requests 2.32.3 which is incompatible.\n",
      "botocore 1.27.28 requires urllib3<1.27,>=1.25.4, but you have urllib3 2.2.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install --ignore-installed tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cd6e1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m venv myenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14e74d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 24.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\anush\\myenv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipykernel\n",
      "  Downloading ipykernel-6.29.5-py3-none-any.whl (117 kB)\n",
      "     ------------------------------------ 117.2/117.2 KB 253.4 kB/s eta 0:00:00\n",
      "Collecting nest-asyncio\n",
      "  Downloading nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
      "Collecting packaging\n",
      "  Using cached packaging-24.1-py3-none-any.whl (53 kB)\n",
      "Collecting traitlets>=5.4.0\n",
      "  Downloading traitlets-5.14.3-py3-none-any.whl (85 kB)\n",
      "     -------------------------------------- 85.4/85.4 KB 141.5 kB/s eta 0:00:00\n",
      "Collecting matplotlib-inline>=0.1\n",
      "  Downloading matplotlib_inline-0.1.7-py3-none-any.whl (9.9 kB)\n",
      "Collecting debugpy>=1.6.5\n",
      "  Downloading debugpy-1.8.3.zip (4.6 MB)\n",
      "     ---------------------------------------- 4.6/4.6 MB 1.2 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting jupyter-client>=6.1.12\n",
      "  Downloading jupyter_client-8.6.2-py3-none-any.whl (105 kB)\n",
      "     ------------------------------------ 105.9/105.9 KB 468.9 kB/s eta 0:00:00\n",
      "Collecting pyzmq>=24\n",
      "  Downloading pyzmq-26.1.0-cp39-cp39-win_amd64.whl (722 kB)\n",
      "     -------------------------------------- 722.7/722.7 KB 1.6 MB/s eta 0:00:00\n",
      "Collecting ipython>=7.23.1\n",
      "  Downloading ipython-8.18.1-py3-none-any.whl (808 kB)\n",
      "     -------------------------------------- 808.2/808.2 KB 2.0 MB/s eta 0:00:00\n",
      "Collecting jupyter-core!=5.0.*,>=4.12\n",
      "  Downloading jupyter_core-5.7.2-py3-none-any.whl (28 kB)\n",
      "Collecting comm>=0.1.1\n",
      "  Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
      "Collecting psutil\n",
      "  Downloading psutil-6.0.0-cp37-abi3-win_amd64.whl (257 kB)\n",
      "     -------------------------------------- 257.4/257.4 KB 2.0 MB/s eta 0:00:00\n",
      "Collecting tornado>=6.1\n",
      "  Downloading tornado-6.4.1-cp38-abi3-win_amd64.whl (438 kB)\n",
      "     -------------------------------------- 438.5/438.5 KB 1.8 MB/s eta 0:00:00\n",
      "Collecting colorama\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Collecting pygments>=2.4.0\n",
      "  Using cached pygments-2.18.0-py3-none-any.whl (1.2 MB)\n",
      "Collecting prompt-toolkit<3.1.0,>=3.0.41\n",
      "  Downloading prompt_toolkit-3.0.47-py3-none-any.whl (386 kB)\n",
      "     -------------------------------------- 386.4/386.4 KB 2.4 MB/s eta 0:00:00\n",
      "Collecting decorator\n",
      "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
      "Collecting stack-data\n",
      "  Downloading stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
      "Collecting typing-extensions\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Collecting jedi>=0.16\n",
      "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
      "     ---------------------------------------- 1.6/1.6 MB 2.4 MB/s eta 0:00:00\n",
      "Collecting exceptiongroup\n",
      "  Downloading exceptiongroup-1.2.2-py3-none-any.whl (16 kB)\n",
      "Collecting python-dateutil>=2.8.2\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "     -------------------------------------- 229.9/229.9 KB 2.8 MB/s eta 0:00:00\n",
      "Collecting importlib-metadata>=4.8.3\n",
      "  Using cached importlib_metadata-8.2.0-py3-none-any.whl (25 kB)\n",
      "Collecting pywin32>=300\n",
      "  Downloading pywin32-306-cp39-cp39-win_amd64.whl (9.3 MB)\n",
      "     ---------------------------------------- 9.3/9.3 MB 3.2 MB/s eta 0:00:00\n",
      "Collecting platformdirs>=2.5\n",
      "  Downloading platformdirs-4.2.2-py3-none-any.whl (18 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Using cached zipp-3.19.2-py3-none-any.whl (9.0 kB)\n",
      "Collecting parso<0.9.0,>=0.8.3\n",
      "  Downloading parso-0.8.4-py2.py3-none-any.whl (103 kB)\n",
      "     -------------------------------------- 103.7/103.7 KB 5.8 MB/s eta 0:00:00\n",
      "Collecting wcwidth\n",
      "  Downloading wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
      "Collecting six>=1.5\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting pure-eval\n",
      "  Downloading pure_eval-0.2.3-py3-none-any.whl (11 kB)\n",
      "Collecting asttokens>=2.1.0\n",
      "  Downloading asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n",
      "Collecting executing>=1.2.0\n",
      "  Downloading executing-2.0.1-py2.py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: debugpy\n",
      "  Building wheel for debugpy (pyproject.toml): started\n",
      "  Building wheel for debugpy (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for debugpy: filename=debugpy-1.8.3-cp39-cp39-win_amd64.whl size=4593802 sha256=0182c2206b1ac82abdfbdb7e0e50e493dad4b5e20794e4a4082756a9ff37dc56\n",
      "  Stored in directory: c:\\users\\anush\\appdata\\local\\pip\\cache\\wheels\\3a\\6d\\a7\\a78623082422ac33b888396aedf558f614dd76a29a1ec4f8ff\n",
      "Successfully built debugpy\n",
      "Installing collected packages: wcwidth, pywin32, pure-eval, zipp, typing-extensions, traitlets, tornado, six, pyzmq, pygments, psutil, prompt-toolkit, platformdirs, parso, packaging, nest-asyncio, executing, exceptiongroup, decorator, debugpy, colorama, python-dateutil, matplotlib-inline, jupyter-core, jedi, importlib-metadata, comm, asttokens, stack-data, jupyter-client, ipython, ipykernel\n",
      "Successfully installed asttokens-2.4.1 colorama-0.4.6 comm-0.2.2 debugpy-1.8.3 decorator-5.1.1 exceptiongroup-1.2.2 executing-2.0.1 importlib-metadata-8.2.0 ipykernel-6.29.5 ipython-8.18.1 jedi-0.19.1 jupyter-client-8.6.2 jupyter-core-5.7.2 matplotlib-inline-0.1.7 nest-asyncio-1.6.0 packaging-24.1 parso-0.8.4 platformdirs-4.2.2 prompt-toolkit-3.0.47 psutil-6.0.0 pure-eval-0.2.3 pygments-2.18.0 python-dateutil-2.9.0.post0 pywin32-306 pyzmq-26.1.0 six-1.16.0 stack-data-0.6.3 tornado-6.4.1 traitlets-5.14.3 typing-extensions-4.12.2 wcwidth-0.2.13 zipp-3.19.2\n"
     ]
    }
   ],
   "source": [
    "!myenv\\Scripts\\python -m pip install ipykernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "055c4f95",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (4015635987.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\anush\\AppData\\Local\\Temp\\ipykernel_39480\\4015635987.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    myenv\\Scripts\\python.exe -m pip install --upgrade pip\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": [
    "myenv\\Scripts\\python.exe -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c283a4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (2.17.0)\n",
      "Collecting numpy==1.21.6\n",
      "  Using cached numpy-1.21.6-cp39-cp39-win_amd64.whl (14.0 MB)\n",
      "Collecting scipy==1.9.0\n",
      "  Downloading scipy-1.9.0-cp39-cp39-win_amd64.whl (38.6 MB)\n",
      "     ---------------------------------------- 38.6/38.6 MB 3.7 MB/s eta 0:00:00\n",
      "Collecting daal==2021.4.0\n",
      "  Using cached daal-2021.4.0-py2.py3-none-win_amd64.whl (69.0 MB)\n",
      "Collecting pyqt5==5.12.3\n",
      "  Using cached PyQt5-5.12.3-5.12.10-cp35.cp36.cp37.cp38.cp39-none-win_amd64.whl (51.4 MB)\n",
      "Collecting pyqtwebengine==5.12.1\n",
      "  Using cached PyQtWebEngine-5.12.1-5.12.10-cp35.cp36.cp37.cp38.cp39-none-win_amd64.whl (49.7 MB)\n",
      "Collecting ruamel-yaml==0.17.21\n",
      "  Downloading ruamel.yaml-0.17.21-py3-none-any.whl (109 kB)\n",
      "     -------------------------------------- 109.5/109.5 kB 2.2 MB/s eta 0:00:00\n",
      "Collecting tbb==2021.*\n",
      "  Using cached tbb-2021.13.0-py3-none-win_amd64.whl (286 kB)\n",
      "Requirement already satisfied: PyQt5_sip<13,>=4.19.14 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from pyqt5==5.12.3) (12.15.0)\n",
      "Collecting ruamel.yaml.clib>=0.2.6\n",
      "  Downloading ruamel.yaml.clib-0.2.8-cp39-cp39-win_amd64.whl (118 kB)\n",
      "     -------------------------------------- 118.4/118.4 kB 3.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from tensorflow) (2.17.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.17.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.3.0)\n",
      "INFO: pip is looking at multiple versions of tensorflow to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.17.0-cp39-cp39-win_amd64.whl (2.0 kB)\n",
      "  Downloading tensorflow-2.16.2-cp39-cp39-win_amd64.whl (2.1 kB)\n",
      "Collecting tensorflow-intel==2.16.2\n",
      "  Downloading tensorflow_intel-2.16.2-cp39-cp39-win_amd64.whl (376.9 MB)\n",
      "     -------------------------------------- 376.9/376.9 MB 2.2 MB/s eta 0:00:00\n",
      "Collecting ml-dtypes~=0.3.1\n",
      "  Downloading ml_dtypes-0.3.2-cp39-cp39-win_amd64.whl (127 kB)\n",
      "     -------------------------------------- 127.7/127.7 kB 3.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (72.1.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (4.25.4)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.16.1-cp39-cp39-win_amd64.whl (2.1 kB)\n",
      "Collecting tensorflow-intel==2.16.1\n",
      "  Downloading tensorflow_intel-2.16.1-cp39-cp39-win_amd64.whl (376.9 MB)\n",
      "     -------------------------------------- 376.9/376.9 MB 2.8 MB/s eta 0:00:00\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.15.1-cp39-cp39-win_amd64.whl (2.1 kB)\n",
      "Collecting tensorflow-intel==2.15.1\n",
      "  Downloading tensorflow_intel-2.15.1-cp39-cp39-win_amd64.whl (300.8 MB)\n",
      "     -------------------------------------- 300.8/300.8 MB 2.5 MB/s eta 0:00:00\n",
      "Collecting keras<2.16,>=2.15.0\n",
      "  Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 3.9 MB/s eta 0:00:00\n",
      "Collecting tensorboard<2.16,>=2.15\n",
      "  Downloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
      "     ---------------------------------------- 5.5/5.5 MB 4.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from tensorflow-intel==2.15.1->tensorflow) (0.31.0)\n",
      "Collecting wrapt<1.15,>=1.11.0\n",
      "  Downloading wrapt-1.14.1-cp39-cp39-win_amd64.whl (35 kB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from tensorflow-intel==2.15.1->tensorflow) (1.65.4)\n",
      "Collecting tensorflow-estimator<2.16,>=2.15.0\n",
      "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
      "     -------------------------------------- 442.0/442.0 kB 4.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from tensorflow-intel==2.15.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from tensorflow-intel==2.15.1->tensorflow) (2.1.0)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.15.0-cp39-cp39-win_amd64.whl (2.1 kB)\n",
      "Collecting tensorflow-intel==2.15.0\n",
      "  Downloading tensorflow_intel-2.15.0-cp39-cp39-win_amd64.whl (300.8 MB)\n",
      "     -------------------------------------- 300.8/300.8 MB 2.5 MB/s eta 0:00:00\n",
      "Collecting ml-dtypes~=0.2.0\n",
      "  Downloading ml_dtypes-0.2.0-cp39-cp39-win_amd64.whl (938 kB)\n",
      "     -------------------------------------- 938.4/938.4 kB 4.0 MB/s eta 0:00:00\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.14.1-cp39-cp39-win_amd64.whl (2.1 kB)\n",
      "Collecting tensorflow-intel==2.14.1\n",
      "  Downloading tensorflow_intel-2.14.1-cp39-cp39-win_amd64.whl (284.1 MB)\n",
      "     -------------------------------------- 284.1/284.1 MB 2.5 MB/s eta 0:00:00\n",
      "Collecting tensorflow-estimator<2.15,>=2.14.0\n",
      "  Downloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl (440 kB)\n",
      "     -------------------------------------- 440.7/440.7 kB 3.1 MB/s eta 0:00:00\n",
      "Collecting keras<2.15,>=2.14.0\n",
      "  Downloading keras-2.14.0-py3-none-any.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 3.4 MB/s eta 0:00:00\n",
      "Collecting tensorboard<2.15,>=2.14\n",
      "  Downloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n",
      "     ---------------------------------------- 5.5/5.5 MB 2.7 MB/s eta 0:00:00\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.14.0-cp39-cp39-win_amd64.whl (2.1 kB)\n",
      "Collecting tensorflow-intel==2.14.0\n",
      "  Downloading tensorflow_intel-2.14.0-cp39-cp39-win_amd64.whl (284.1 MB)\n",
      "     -------------------------------------- 284.1/284.1 MB 2.9 MB/s eta 0:00:00\n",
      "INFO: pip is looking at multiple versions of tensorflow to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.13.1-cp39-cp39-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.13.1\n",
      "  Downloading tensorflow_intel-2.13.1-cp39-cp39-win_amd64.whl (276.5 MB)\n",
      "     -------------------------------------- 276.5/276.5 MB 2.4 MB/s eta 0:00:00\n",
      "Collecting tensorboard<2.14,>=2.13\n",
      "  Using cached tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "Collecting keras<2.14,>=2.13.1\n",
      "  Using cached keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting tensorflow-estimator<2.14,>=2.13.0\n",
      "  Using cached tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.13.0-cp39-cp39-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.13.0\n",
      "  Using cached tensorflow_intel-2.13.0-cp39-cp39-win_amd64.whl (276.5 MB)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.12.1-cp39-cp39-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.12.1\n",
      "  Downloading tensorflow_intel-2.12.1-cp39-cp39-win_amd64.whl (272.8 MB)\n",
      "     -------------------------------------- 272.8/272.8 MB 2.7 MB/s eta 0:00:00\n",
      "Collecting keras<2.13,>=2.12.0\n",
      "  Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 3.1 MB/s eta 0:00:00\n",
      "Collecting tensorflow-estimator<2.13,>=2.12.0\n",
      "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
      "     -------------------------------------- 440.7/440.7 kB 3.9 MB/s eta 0:00:00\n",
      "Collecting tensorboard<2.13,>=2.12\n",
      "  Downloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
      "     ---------------------------------------- 5.6/5.6 MB 3.8 MB/s eta 0:00:00\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.12.0-cp39-cp39-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.12.0\n",
      "  Downloading tensorflow_intel-2.12.0-cp39-cp39-win_amd64.whl (272.8 MB)\n",
      "     -------------------------------------- 272.8/272.8 MB 2.0 MB/s eta 0:00:00\n",
      "Collecting jax>=0.3.15\n",
      "  Downloading jax-0.4.30-py3-none-any.whl (2.0 MB)\n",
      "     ---------------------------------------- 2.0/2.0 MB 1.7 MB/s eta 0:00:00\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.11.1-cp39-cp39-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.11.1\n",
      "  Downloading tensorflow_intel-2.11.1-cp39-cp39-win_amd64.whl (266.3 MB)\n",
      "     -------------------------------------- 266.3/266.3 MB 2.7 MB/s eta 0:00:00\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.6-cp39-cp39-win_amd64.whl (895 kB)\n",
      "     -------------------------------------- 895.9/895.9 kB 3.3 MB/s eta 0:00:00\n",
      "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
      "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
      "     -------------------------------------- 439.2/439.2 kB 4.6 MB/s eta 0:00:00\n",
      "Collecting keras<2.12,>=2.11.0\n",
      "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 4.3 MB/s eta 0:00:00\n",
      "Collecting tensorboard<2.12,>=2.11\n",
      "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
      "     ---------------------------------------- 6.0/6.0 MB 4.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from tensorflow-intel==2.11.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from tensorflow-intel==2.11.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.1->tensorflow) (0.44.0)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.32.0-py2.py3-none-any.whl (195 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow) (3.0.3)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "     -------------------------------------- 781.3/781.3 kB 3.8 MB/s eta 0:00:00\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow) (3.6)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.4.0-py3-none-any.whl (9.5 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow) (0.2.8)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow) (8.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.7.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow) (3.19.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: tensorboard-plugin-wit, tbb, tensorflow-estimator, tensorboard-data-server, ruamel.yaml.clib, rsa, pyqt5, protobuf, oauthlib, numpy, keras, gast, daal, cachetools, scipy, ruamel-yaml, requests-oauthlib, pyqtwebengine, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: tbb\n",
      "    Found existing installation: TBB 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Cannot uninstall 'TBB'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow numpy==1.21.6 scipy==1.9.0 daal==2021.4.0 pyqt5==5.12.3 pyqtwebengine==5.12.1 ruamel-yaml==0.17.21\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99cd8c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88492e8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "\n",
    "# Example data (use your own dataset here)\n",
    "X, y = np.load('Features.xlsx'), np.load('Labels.xlsx')\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(input_dim,)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "859b4bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          girl      boy       \n",
      "girl      3         1         \n",
      "boy       1         2         \n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Given true and predicted labels\n",
    "truth = ['girl', 'girl', 'boy', 'girl', 'girl', 'boy', 'boy']\n",
    "predicted = ['girl', 'boy', 'boy', 'girl', 'girl', 'girl', 'boy']\n",
    "\n",
    "# Initialize confusion matrix\n",
    "confusion_matrix = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "# Compute the confusion matrix\n",
    "for t, p in zip(truth, predicted):\n",
    "    confusion_matrix[t][p] += 1\n",
    "\n",
    "# Convert confusion matrix to a readable format\n",
    "def print_confusion_matrix(cm, labels):\n",
    "    print(f\"{'':<10}\", end=\"\")\n",
    "    for label in labels:\n",
    "        print(f\"{label:<10}\", end=\"\")\n",
    "    print()\n",
    "    for label in labels:\n",
    "        print(f\"{label:<10}\", end=\"\")\n",
    "        for l in labels:\n",
    "            print(f\"{cm[label].get(l, 0):<10}\", end=\"\")\n",
    "        print()\n",
    "\n",
    "# List of labels\n",
    "labels = ['girl', 'boy']\n",
    "\n",
    "# Print the confusion matrix\n",
    "print_confusion_matrix(confusion_matrix, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "484211c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "import pandas as pd\n",
    "\n",
    "def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names, \n",
    "    )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('Truth')\n",
    "    plt.xlabel('Prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38b8be1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names, \n",
    "    )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('Truth')\n",
    "    plt.xlabel('Prediction')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d53ef973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from scikit-learn) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from scikit-learn) (1.9.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages (from scikit-learn) (2.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\anush\\onedrive\\documents\\python scripts\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ee510f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Define the true and predicted labels\n",
    "truth = ['girl', 'girl', 'boy', 'girl', 'girl', 'boy', 'boy']\n",
    "predicted = ['girl', 'boy', 'boy', 'girl', 'girl', 'girl', 'boy']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c3695ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[3 1]\n",
      " [1 2]]\n",
      "\n",
      "Accuracy: 0.71\n",
      "Precision: [0.75       0.66666667]\n",
      "Recall: [0.75       0.66666667]\n",
      "F1 Score: [0.75       0.66666667]\n"
     ]
    }
   ],
   "source": [
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(truth, predicted, labels=['girl', 'boy'])\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(truth, predicted)\n",
    "\n",
    "# Calculate precision, recall, and F1 score for each class\n",
    "precision = precision_score(truth, predicted, average=None, labels=['girl', 'boy'])\n",
    "recall = recall_score(truth, predicted, average=None, labels=['girl', 'boy'])\n",
    "f1 = f1_score(truth, predicted, average=None, labels=['girl', 'boy'])\n",
    "\n",
    "# Print results\n",
    "print(f\"Confusion Matrix:\\n{cm}\\n\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59eb72b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
